{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOVFEZfK0l0h7mscnq99urr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subhashjprasad/pdf-summarizer/blob/main/PDFSummarizerEasyUse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Following Cell Once"
      ],
      "metadata": {
        "id": "WmWkxDoq8Gkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install levenshtein\n",
        "\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "import re\n",
        "from PIL import Image\n",
        "\n",
        "from transformers import NougatProcessor, VisionEncoderDecoderModel\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "\n",
        "processor = NougatProcessor.from_pretrained(\"facebook/nougat-base\")\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"facebook/nougat-base\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "!apt-get install poppler-utils\n",
        "!pip install pdf2image\n",
        "\n",
        "from pdf2image import convert_from_path, convert_from_bytes\n",
        "from IPython.display import display, Image\n",
        "\n",
        "import textwrap\n",
        "wrapper = textwrap.TextWrapper(width=100)\n",
        "\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "hf_name = 'pszemraj/led-large-book-summary'\n",
        "\n",
        "summarizer = pipeline(\n",
        "    \"summarization\",\n",
        "    hf_name,\n",
        "    device=0 if torch.cuda.is_available() else -1,\n",
        ")"
      ],
      "metadata": {
        "id": "qo_SEPn4HErD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rerun Following Cells For Each New PDF"
      ],
      "metadata": {
        "id": "OqMcqii0_VFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "pdf_path = '_____.pdf' # replace with pdf path\n",
        "images = convert_from_bytes(open(pdf_path, 'rb').read(), size=800)\n",
        "\n",
        "pixel_values = []\n",
        "for i in range(len(images)):\n",
        "    pixel_values.append(processor(images[i], return_tensors=\"pt\").pixel_values)\n",
        "\n",
        "outputs = []\n",
        "for i in range(len(pixel_values)):\n",
        "    outputs.append(model.generate(\n",
        "        pixel_values[i].to(device),\n",
        "        min_length=1,\n",
        "        max_new_tokens=5000,\n",
        "        bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
        "    ))\n",
        "\n",
        "full_text = []\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    sequence = processor.batch_decode(outputs[i], skip_special_tokens=True)[0]\n",
        "    sequence = processor.post_process_generation(sequence, fix_markdown=False)\n",
        "    full_text.append(sequence)\n",
        "\n",
        "    sequence_list = wrapper.wrap(text = sequence)\n",
        "    print(f\"Page {i + 1}:\", '\\n')\n",
        "    for element in sequence_list:\n",
        "        print(element)\n",
        "    print('\\n')\n",
        "\n",
        "page_number = 1\n",
        "summary_text = []\n",
        "\n",
        "for page in full_text:\n",
        "    print(f\"Page {page_number} Summary: \\n------------------------\\n\")\n",
        "    summary_text.append(f\"Page {page_number} Summary: \\n------------------------\\n\")\n",
        "\n",
        "    result = summarizer(\n",
        "        page,\n",
        "        min_length=16,\n",
        "        max_length=512,\n",
        "        no_repeat_ngram_size=3,\n",
        "        encoder_no_repeat_ngram_size=3,\n",
        "        repetition_penalty=3.5,\n",
        "        num_beams=4,\n",
        "        early_stopping=True,\n",
        "    )\n",
        "\n",
        "    result_wrap_list = wrapper.wrap(text = result[0]['summary_text'])\n",
        "    for element in result_wrap_list:\n",
        "        print(element)\n",
        "        summary_text.append(element)\n",
        "\n",
        "    print(\"\\n------------------------\\n\")\n",
        "    summary_text.append(\"\\n------------------------\\n\")\n",
        "    page_number += 1"
      ],
      "metadata": {
        "id": "OWzBIhqAJmiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for s in summary_text:\n",
        "    print(s)"
      ],
      "metadata": {
        "id": "MSrtw4uWnl2e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}